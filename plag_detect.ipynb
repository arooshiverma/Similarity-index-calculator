{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1db7ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy as sp\n",
    "nlp = sp.load(\"en_core_web_lg\")\n",
    "#Uncomment the below line to use en_core_web_sm\n",
    "#nlp = sp.load(\"en_core_web_sm\")\n",
    "import nltk\n",
    "from nltk.corpus import wordnet   #Import wordnet from the NLTK\n",
    "from nltk.stem.porter import *\n",
    "from bert_score import score\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ede5203a",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1 = \"doc1.txt\"\n",
    "doc2 = \"doc2.txt\"\n",
    "#For testing with non plagiarized doc, uncomment the below line\n",
    "#doc2 = \"lab5_non_plag.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f20318f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLines(filename):\n",
    "    f = open(filename, 'r')\n",
    "    s = f.read();\n",
    "    #removing unecessary punctuations\n",
    "    s = s.replace(',', ' ')\n",
    "    s = s.replace(';', ' ')\n",
    "    s = s.replace('-', ' ')\n",
    "    s = s.lower()\n",
    "    #splitting sentence wise\n",
    "    ls = s.split('.')\n",
    "    lines = []\n",
    "    for i in ls:    \n",
    "        x = i.split()\n",
    "        if(x != []):\n",
    "            lines.append(x)\n",
    "            \n",
    "    return lines\n",
    "def remove_sw(lines):\n",
    "    all_stopwords = list(sp.lang.en.stop_words.STOP_WORDS)\n",
    "    #print(all_stopwords)\n",
    "    l_sw = []\n",
    "    stemmer = PorterStemmer()\n",
    "    for i in range(len(lines)):\n",
    "        temp = ''\n",
    "        for word in lines[i]:\n",
    "            if word not in all_stopwords:\n",
    "                if(temp == ''):\n",
    "                    #temp = stemmer.stem(word)\n",
    "                    temp = word\n",
    "                else:\n",
    "                    #temp = temp + ' ' + stemmer.stem(word)\n",
    "                    temp = temp + ' ' + word\n",
    "            \n",
    "        l_sw.append(temp)\n",
    "    return l_sw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6abb413a",
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = getLines(doc1)\n",
    "l2 = getLines(doc2)\n",
    "#Removing stop words and stemming\n",
    "ls1 = remove_sw(l1)\n",
    "ls2 = remove_sw(l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e97f5556",
   "metadata": {},
   "outputs": [],
   "source": [
    "#different kinds of similarity functions\n",
    "def cosSim(s1, s2):\n",
    "    similarity_ = np.dot(s1, s2) / (norm(s1) * norm(s2))\n",
    "    return similarity_\n",
    "\n",
    "def bertSim(s1, s2, idf=False):\n",
    "    p, _, _ = score([s1], [s2], lang='en', idf=True)\n",
    "    return p.item()\n",
    "def spacySimil(s1, s2):\n",
    "    s1 = nlp(s1)\n",
    "    s2 = nlp(s2)\n",
    "    return s1.similarity(s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21525e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSentSimil(s1, s2):\n",
    "    #Uncomment the line below to use Bert similarity\n",
    "    #return bertSim(s1, s2)\n",
    "    return spacySimil(s1, s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3058bbb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 22/22 [01:17<00:00,  3.51s/it]\n"
     ]
    }
   ],
   "source": [
    "graph = [[0.0 for y in range(len(ls2))] for x in range(len(ls1))]\n",
    "for i in tqdm(range(len(ls1))):\n",
    "    for j in range(len(ls2)):\n",
    "        graph[i][j] = getSentSimil(ls1[i], ls2[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f649c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertToSquare(graph):\n",
    "    l1, l2 = len(graph), len(graph[0])\n",
    "    g = [[0.01 for x in range(l2)] for y in range(l1+l2)]\n",
    "    if(l1>l2):\n",
    "        g = [[0.01 for x in range(l1+l2)] for y in range(l1)]\n",
    "    for i in range(l1):\n",
    "        for j in range(l2):\n",
    "            g[i][j] = graph[i][j]\n",
    "    return g\n",
    "\n",
    "def removeLowMatches(graph):\n",
    "    for i in range(len(graph)):\n",
    "        for j in range(len(graph[0])):\n",
    "            if(graph[i][j]<=0.6):\n",
    "                graph[i][j] = 0.0\n",
    "    return graph\n",
    "\n",
    "def maxMatching(graph, n1, n2):\n",
    "    #print(n1, n2)\n",
    "    ret = []\n",
    "    st = set()\n",
    "    if(n1<n2):\n",
    "        for i in range(n1):\n",
    "            ind = -1\n",
    "            maxnum = 0\n",
    "            #print(i)\n",
    "            for j in range(n2):\n",
    "                if(graph[i][j]>=maxnum and (j not in st)):\n",
    "                    ind = j\n",
    "                    maxnum = graph[i][j]\n",
    "            \n",
    "            ret.append((i, ind))\n",
    "            st.add(ind)\n",
    "    else:\n",
    "        for j in range(n2):\n",
    "            ind = -1\n",
    "            maxnum = 0\n",
    "            for i in range(n1):\n",
    "                if(graph[i][j]>=maxnum and (i not in st)):\n",
    "                    ind = i\n",
    "                    maxnum = graph[i][j]\n",
    "            ret.append((ind, j))\n",
    "            st.add(ind)\n",
    "    ret.sort()\n",
    "    return(ret)\n",
    "            \n",
    "def getOptimalMatching(graph):\n",
    "    #print(graph)\n",
    "    graph = removeLowMatches(graph)\n",
    "    n1, n2 = len(graph), len(graph[0])\n",
    "    graph = convertToSquare(graph)\n",
    "    #return maxMatching(graph, n1, n2)\n",
    "    #print(graph)\n",
    "    graph = -1*np.array(graph)\n",
    "    #print(graph)\n",
    "    rc, cc = linear_sum_assignment(graph)\n",
    "    ret = []\n",
    "    for i in range(len(rc)):\n",
    "        ret.append((rc[i], cc[i]))\n",
    "    #print(rc)\n",
    "    #print(cc)\n",
    "    return(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7fc823d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal matching of sentences:\n",
      "\n",
      "\n",
      "0 0 hello arooshi verma  ----  hi avanika\n",
      "1 1 4th year dual degree student iit bhubaneswar  ----  study 3rd year iit indore\n",
      "2 9 sample data plagiarism detector  ----  computer electronic device perform tasks like messaging calculations data storage printing etc\n",
      "3 2 working emotion detection poem audios  ----  working feeling detection audios data cheating detector\n",
      "4 25 dataset created hindi language  ----  None\n",
      "5 3 forensic science known forensics application science law  ----  forensic science uses highly developed tech find evidence variety fields\n",
      "6 10 uses highly developed technology uncover scientific evidence variety fields  ----  computers developed 1940s\n",
      "7 4 modern forensic science broad range applications  ----  broad range applications\n",
      "8 5 civil cases forgeries fraud negligence  ----  civil cases fraud negligence\n",
      "9 6 common use forensic science investigate criminal cases involving victim assault robbery kidnapping rape murder  ----  usually forensics investigate assualt rape kidnapping robbery\n",
      "10 7 forensic science monitoring compliance countries international agreements nuclear non proliferation  ----  comes play monitoring compliance interational agreements\n",
      "11 8 presence animals essential maintains balance ecosystem  ----  presence animals essential maintains balance ecosystem\n",
      "12 15 today world animals serve companions help reduce stress anxiety depression loneliness  ----  animals best companions today's world reduce tension stress\n",
      "13 16 organism unique place food chain contributes maintaining existence life planet  ----  food chain unique place organism contribute maintaining life earth\n",
      "14 17 man learned early complex advanced mind superior animal earth  ----  man learned early complex advanced mind superior animal earth\n",
      "15 24 sisters family  ----  None\n",
      "16 23 elder sister younger  ----  None\n",
      "17 22 maybe sister funniest greatest perfect blindly trust  ----  None\n",
      "18 20 easily laugh  ----  None\n",
      "19 19 effortlessly feel great  ----  None\n",
      "20 21 suggesting supporting  ----  None\n",
      "21 18 best advisors got life  ----  None\n"
     ]
    }
   ],
   "source": [
    "graph = np.array(graph)\n",
    "opti = getOptimalMatching(graph)\n",
    "print(\"Optimal matching of sentences:\\n\\n\")\n",
    "for i in range(len(opti)):\n",
    "    p1 = \"None\"\n",
    "    if(opti[i][0] < len(ls1)):\n",
    "        p1 = ls1[opti[i][0]]\n",
    "    p2 = \"None\"\n",
    "    if(opti[i][1] < len(ls2)):\n",
    "        p2 = ls2[opti[i][1]]\n",
    "    print(opti[i][0], opti[i][1], p1, \" ---- \", p2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "558565be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDocSimilarityScore(matching, graph):\n",
    "    sum1 = 0.0\n",
    "    #print(matching)\n",
    "    for i in range(len(matching)):\n",
    "        ind1, ind2 = matching[i][0], matching[i][1]\n",
    "        if(ind1>=len(graph) or ind2>=len(graph[ind1])):\n",
    "            continue\n",
    "        sum1 += graph[ind1][ind2]\n",
    "        #print(i, ind1, ind2, graph[ind1][ind2])\n",
    "    return(sum1/(0.5*(len(graph)+len(graph[0]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "13b06e72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity score: 0.5868503683561415\n",
      "Chance of document being plagiarized\n"
     ]
    }
   ],
   "source": [
    "simil = getDocSimilarityScore(opti, graph)\n",
    "threshold = 0.5\n",
    "print(\"Similarity score:\", simil)\n",
    "if(simil > 0.6):\n",
    "    print(\"High chance document is plagiarized.\")\n",
    "elif(simil > 0.4):\n",
    "    print(\"Chance of document being plagiarized\")\n",
    "else:\n",
    "    print(\"Document not plagiarized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eaa3a66c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 1, 0, 1), (7, 11, 4, 8), (12, 14, 15, 17)]\n"
     ]
    }
   ],
   "source": [
    "locals = []\n",
    "i = 1\n",
    "while(i<len(ls1)):\n",
    "    curr = i-1\n",
    "    cnt = 1\n",
    "    while(i<len(opti) and opti[i][0]<len(ls1) and opti[i-1][1]<len(ls2)) and opti[i][1]-opti[i-1][1] == 1:\n",
    "        cnt+=1\n",
    "        i+=1\n",
    "    if(curr==i-1):\n",
    "        i+=1\n",
    "    else:\n",
    "        locals.append((curr, curr+cnt-1, opti[curr][1], opti[curr+cnt-1][1]))\n",
    "print(locals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9c0422a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Line numbers  0 to 1 of the first document match lines 0 to 1 of the second document\n",
      "Line numbers  7 to 11 of the first document match lines 4 to 8 of the second document\n",
      "Line numbers  12 to 14 of the first document match lines 15 to 17 of the second document\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(locals)):\n",
    "    print(\"Line numbers \",locals[i][0],\"to\",locals[i][1], \"of the first document match lines\",locals[i][2],\"to\",locals[i][3],\"of the second document\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3312719",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sflab",
   "language": "python",
   "name": "sflab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
